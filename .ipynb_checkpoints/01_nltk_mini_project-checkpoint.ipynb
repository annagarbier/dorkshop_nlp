{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A mini Mad Libs using tokenization and POS tagging\n",
    "\n",
    "1. [Get some text to play with](#01)\n",
    "1. [Tokenize the text](#02)\n",
    "1. [Tag each token](#03)\n",
    "1. [Explore the tags](#04)\n",
    "1. [Using tags for simple analytics](#05)\n",
    "1. [Using tags for procedural modifications](#06)\n",
    "1. [Ideas for going further](#07)\n",
    "\n",
    "<hr>\n",
    "\n",
    "## <span id=\"01\">Get some text to play with</span>\n",
    "\n",
    "`Natural Language Tooklik` (usually referred to as `nltk`) is a Python library made for processing 'natural' language. We'll use several of the library's features in this code, and will introduce each as we go.\n",
    "\n",
    "\n",
    "In this first section, we will use `nltk` to download a set of texts from the Project Gutenberg **corpus**.\n",
    "\n",
    "The [Project Gutenberg](https://www.gutenberg.org/) corpus contains 60,000 public domain e-books made available for non-commercial use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Gutenberg corpus.\n",
    "from nltk.corpus import gutenberg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['austen-emma.txt',\n",
       " 'austen-persuasion.txt',\n",
       " 'austen-sense.txt',\n",
       " 'bible-kjv.txt',\n",
       " 'blake-poems.txt',\n",
       " 'bryant-stories.txt',\n",
       " 'burgess-busterbrown.txt',\n",
       " 'carroll-alice.txt',\n",
       " 'chesterton-ball.txt',\n",
       " 'chesterton-brown.txt',\n",
       " 'chesterton-thursday.txt',\n",
       " 'edgeworth-parents.txt',\n",
       " 'melville-moby_dick.txt',\n",
       " 'milton-paradise.txt',\n",
       " 'shakespeare-caesar.txt',\n",
       " 'shakespeare-hamlet.txt',\n",
       " 'shakespeare-macbeth.txt',\n",
       " 'whitman-leaves.txt']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Look at the file names for the texts that are included in the corpus.\n",
    "gutenberg.fileids()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store an entire story as raw text in a string variable.\n",
    "alice_text = gutenberg.raw('carroll-alice.txt')\n",
    "\n",
    "# Print a preview of the text using the variable name.\n",
    "# print(alice_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Alice was beginning to get very tired of sitting by her sister on the\n",
      "bank, and of having nothing to do: once or twice she had peeped into the\n",
      "book her sister was reading, but it had no pictures or conversations in\n",
      "it, 'and what is the use of a book,' thought Alice 'without pictures or\n",
      "conversation?'\n"
     ]
    }
   ],
   "source": [
    "# Grab just the first paragraph of this text using a character range.\n",
    "alice_paragraph = alice_text[90:392]\n",
    "\n",
    "# Print a preview of the paragraph.\n",
    "print(alice_paragraph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "    \n",
    "## <span id=\"02\">Tokenize the text</span>\n",
    "\n",
    "**Tokenization** is the process of turning text into a list of individual **tokens**. \"A token is the technical name for a sequence of characters...that we want to treat as a group.\" ([nltk.org](https://www.nltk.org/book/ch05.html))\n",
    "\n",
    "The most common token is a word (e.g. \"cat\", \"dog\"), but tokens can also be symbols like punctuation marks (e.g. \"?\", \"...\"), emoticons (\":)\"), or sub-word units like [clitics](https://en.wikipedia.org/wiki/Clitic) (e.g. \"'s\", \"n't\"). We could even tokenize a text based on syllables. For this demo, we will tokenize text using nltk's `word_tokenize`.\n",
    "\n",
    "More info: https://www.nltk.org/book/ch05.html\n",
    "\n",
    "### Example invocation\n",
    "\n",
    "```python\n",
    "word_tokenize(\"Alice was beginning to get very tired...\")\n",
    "# Returns ['Alice', 'was', 'beginning', 'to', 'get', 'very', 'tired', '...']\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the word tokenizer.\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Alice', 'was', 'beginning', 'to', 'get', 'very', 'tired', 'of', 'sitting', 'by', 'her', 'sister', 'on', 'the', 'bank', ',', 'and', 'of', 'having', 'nothing', 'to', 'do', ':', 'once', 'or', 'twice', 'she', 'had', 'peeped', 'into', 'the', 'book', 'her', 'sister', 'was', 'reading', ',', 'but', 'it', 'had', 'no', 'pictures', 'or', 'conversations', 'in', 'it', ',', \"'and\", 'what', 'is', 'the', 'use', 'of', 'a', 'book', ',', \"'\", 'thought', 'Alice', \"'without\", 'pictures', 'or', 'conversation', '?', \"'\"]\n"
     ]
    }
   ],
   "source": [
    "# Pass the trimmed text into the tokenizer.\n",
    "alice_paragraph_tokenized = word_tokenize(alice_paragraph)\n",
    "\n",
    "# Print tokenized text.\n",
    "print(alice_paragraph_tokenized)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "## <span id=\"03\">Tag each token</span>\n",
    "\n",
    "A **part-of-speech tagger**, or **POS-tagger**, accepts an ordered list of tokens, and attaches a part of speech tag to each. We will use `Nltk`'s `pos_tag` which applies part-of-speech tags using a data structure called a `tuple`. For example: `('Alice', 'NNP')`.\n",
    "\n",
    "### Example invocation\n",
    "\n",
    "```python\n",
    "pos_tag(['Alice', 'was', 'beginning', 'to', 'get', 'very', 'tired'])\n",
    "# Returns [('Alice', 'NNP'), ('was', 'VBD'), ('beginning', 'VBG'), ('to', 'TO'), ('get', 'VB'), ('very', 'RB'), ('tired', 'JJ')]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import POS tagger.\n",
    "from nltk import pos_tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Alice', 'NNP'), ('was', 'VBD'), ('beginning', 'VBG'), ('to', 'TO'), ('get', 'VB'), ('very', 'RB'), ('tired', 'JJ'), ('of', 'IN'), ('sitting', 'VBG'), ('by', 'IN'), ('her', 'PRP$'), ('sister', 'NN'), ('on', 'IN'), ('the', 'DT'), ('bank', 'NN'), (',', ','), ('and', 'CC'), ('of', 'IN'), ('having', 'VBG'), ('nothing', 'NN'), ('to', 'TO'), ('do', 'VB'), (':', ':'), ('once', 'RB'), ('or', 'CC'), ('twice', 'VB'), ('she', 'PRP'), ('had', 'VBD'), ('peeped', 'VBN'), ('into', 'IN'), ('the', 'DT'), ('book', 'NN'), ('her', 'PRP$'), ('sister', 'NN'), ('was', 'VBD'), ('reading', 'VBG'), (',', ','), ('but', 'CC'), ('it', 'PRP'), ('had', 'VBD'), ('no', 'DT'), ('pictures', 'NNS'), ('or', 'CC'), ('conversations', 'NNS'), ('in', 'IN'), ('it', 'PRP'), (',', ','), (\"'and\", 'VB'), ('what', 'WP'), ('is', 'VBZ'), ('the', 'DT'), ('use', 'NN'), ('of', 'IN'), ('a', 'DT'), ('book', 'NN'), (',', ','), (\"'\", \"''\"), ('thought', 'JJ'), ('Alice', 'NNP'), (\"'without\", 'POS'), ('pictures', 'NNS'), ('or', 'CC'), ('conversation', 'NN'), ('?', '.'), (\"'\", \"''\")]\n"
     ]
    }
   ],
   "source": [
    "# We pass our tokenized text into the part-of-speech tagger.\n",
    "alice_paragraph_tagged = pos_tag(alice_paragraph_tokenized)\n",
    "\n",
    "# Print a preview of the tagged paragraph.\n",
    "print(alice_paragraph_tagged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NNP: noun, proper, singular\n",
      "    Motown Venneboerger Czestochwa Ranzer Conchita Trumplane Christos\n",
      "    Oceanside Escobar Kreisler Sawyer Cougar Yvette Ervin ODI Darryl CTCA\n",
      "    Shannon A.K.C. Meltex Liverpool ...\n"
     ]
    }
   ],
   "source": [
    "# Wait, what do those symbols mean??\n",
    "from nltk.help import upenn_tagset\n",
    "\n",
    "# Print a specific tag description.\n",
    "upenn_tagset('NNP')\n",
    "\n",
    "# Print all tag descriptions.\n",
    "# upenn_tagset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "## <span id=\"04\">Explore the tags</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Alice', 'NNP'), ('was', 'VBD'), ('beginning', 'VBG'), ('to', 'TO'), ('get', 'VB'), ('very', 'RB'), ('tired', 'JJ'), ('of', 'IN'), ('sitting', 'VBG'), ('by', 'IN'), ('her', 'PRP$'), ('sister', 'NN'), ('on', 'IN'), ('the', 'DT'), ('bank', 'NN'), (',', ','), ('and', 'CC'), ('of', 'IN'), ('having', 'VBG'), ('nothing', 'NN'), ('to', 'TO'), ('do', 'VB'), (':', ':'), ('once', 'RB'), ('or', 'CC'), ('twice', 'VB'), ('she', 'PRP'), ('had', 'VBD'), ('peeped', 'VBN'), ('into', 'IN'), ('the', 'DT'), ('book', 'NN'), ('her', 'PRP$'), ('sister', 'NN'), ('was', 'VBD'), ('reading', 'VBG'), (',', ','), ('but', 'CC'), ('it', 'PRP'), ('had', 'VBD'), ('no', 'DT'), ('pictures', 'NNS'), ('or', 'CC'), ('conversations', 'NNS'), ('in', 'IN'), ('it', 'PRP'), (',', ','), (\"'and\", 'VB'), ('what', 'WP'), ('is', 'VBZ'), ('the', 'DT'), ('use', 'NN'), ('of', 'IN'), ('a', 'DT'), ('book', 'NN'), (',', ','), (\"'\", \"''\"), ('thought', 'JJ'), ('Alice', 'NNP'), (\"'without\", 'POS'), ('pictures', 'NNS'), ('or', 'CC'), ('conversation', 'NN'), ('?', '.'), (\"'\", \"''\")]\n"
     ]
    }
   ],
   "source": [
    "# First let's remind ourselves what our data looks like...\n",
    "print(alice_paragraph_tagged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Alice', 'NNP')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get a particular tuple based on its index.\n",
    "alice_paragraph_tagged[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Alice'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get a particular word based on its tuple index.\n",
    "alice_paragraph_tagged[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'NNP'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get a particular POS tag based on its tuple index.\n",
    "alice_paragraph_tagged[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('sister', 'NN')\n",
      "('bank', 'NN')\n",
      "('nothing', 'NN')\n",
      "('book', 'NN')\n",
      "('sister', 'NN')\n",
      "('use', 'NN')\n",
      "('book', 'NN')\n",
      "('conversation', 'NN')\n"
     ]
    }
   ],
   "source": [
    "# Get all tuples with a particule POS tag.\n",
    "for t in alice_paragraph_tagged:\n",
    "    if t[1] == 'NN':\n",
    "        print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sister\n",
      "bank\n",
      "nothing\n",
      "book\n",
      "sister\n",
      "use\n",
      "book\n",
      "conversation\n"
     ]
    }
   ],
   "source": [
    "# Get all words with a particule POS tag.\n",
    "for t in alice_paragraph_tagged:\n",
    "    if t[1] == 'NN':\n",
    "        print(t[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "## <span id=\"05\">Using tags for simple analytics</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count breakdown of POS\n",
    "for t in alice_paragraph_tagged:\n",
    "    if t[1] == 'NN':\n",
    "        print(t[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "## <span id=\"06\">Using tags for procedural modifications</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['Alice', 'NNP'], ['was', 'VBD'], ['beginning', 'VBG'], ['to', 'TO'], ['get', 'VB'], ['very', 'RB'], ['tired', 'JJ'], ['of', 'IN'], ['sitting', 'VBG'], ['by', 'IN'], ['her', 'PRP$'], ['sister', 'NN'], ['on', 'IN'], ['the', 'DT'], ['bank', 'NN'], [',', ','], ['and', 'CC'], ['of', 'IN'], ['having', 'VBG'], ['nothing', 'NN'], ['to', 'TO'], ['do', 'VB'], [':', ':'], ['once', 'RB'], ['or', 'CC'], ['twice', 'VB'], ['she', 'PRP'], ['had', 'VBD'], ['peeped', 'VBN'], ['into', 'IN'], ['the', 'DT'], ['book', 'NN'], ['her', 'PRP$'], ['sister', 'NN'], ['was', 'VBD'], ['reading', 'VBG'], [',', ','], ['but', 'CC'], ['it', 'PRP'], ['had', 'VBD'], ['no', 'DT'], ['pictures', 'NNS'], ['or', 'CC'], ['conversations', 'NNS'], ['in', 'IN'], ['it', 'PRP'], [',', ','], [\"'and\", 'VB'], ['what', 'WP'], ['is', 'VBZ'], ['the', 'DT'], ['use', 'NN'], ['of', 'IN'], ['a', 'DT'], ['book', 'NN'], [',', ','], [\"'\", \"''\"], ['thought', 'JJ'], ['Alice', 'NNP'], [\"'without\", 'POS'], ['pictures', 'NNS'], ['or', 'CC'], ['conversation', 'NN'], ['?', '.'], [\"'\", \"''\"]]\n"
     ]
    }
   ],
   "source": [
    "# Tuples cannot be modified, so fist we want to change\n",
    "# each tuple into a two-item list. Unlike tuples, lists can be modified.\n",
    "\n",
    "# Create an empty list to hold all of our newly-formatted data.\n",
    "alice_paragraph_tagged_list = []\n",
    "\n",
    "# Go through the original data.\n",
    "for t in alice_paragraph_tagged:\n",
    "    # Convert each tuple \"t\" into a list \"l\".\n",
    "    l = list(t)\n",
    "    # Add that new list \"l\" to the data.\n",
    "    alice_paragraph_tagged_list.append(l)\n",
    "\n",
    "# Print the newly formatted data.\n",
    "print(alice_paragraph_tagged_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sister\n",
      "bank\n",
      "nothing\n",
      "book\n",
      "sister\n",
      "use\n",
      "book\n",
      "conversation\n"
     ]
    }
   ],
   "source": [
    "# We can look up words based on part of speech just as we did before.\n",
    "for l in alice_paragraph_tagged_list:\n",
    "    if l[1] == 'NN':\n",
    "        print(l[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['Alice', 'NNP'], ['was', 'VBD'], ['beginning', 'VBG'], ['to', 'TO'], ['get', 'VB'], ['very', 'RB'], ['tired', 'JJ'], ['of', 'IN'], ['sitting', 'VBG'], ['by', 'IN'], ['her', 'PRP$'], ['~~~~~~~', 'NN'], ['on', 'IN'], ['the', 'DT'], ['~~~~~~~', 'NN'], [',', ','], ['and', 'CC'], ['of', 'IN'], ['having', 'VBG'], ['~~~~~~~', 'NN'], ['to', 'TO'], ['do', 'VB'], [':', ':'], ['once', 'RB'], ['or', 'CC'], ['twice', 'VB'], ['she', 'PRP'], ['had', 'VBD'], ['peeped', 'VBN'], ['into', 'IN'], ['the', 'DT'], ['~~~~~~~', 'NN'], ['her', 'PRP$'], ['~~~~~~~', 'NN'], ['was', 'VBD'], ['reading', 'VBG'], [',', ','], ['but', 'CC'], ['it', 'PRP'], ['had', 'VBD'], ['no', 'DT'], ['pictures', 'NNS'], ['or', 'CC'], ['conversations', 'NNS'], ['in', 'IN'], ['it', 'PRP'], [',', ','], [\"'and\", 'VB'], ['what', 'WP'], ['is', 'VBZ'], ['the', 'DT'], ['~~~~~~~', 'NN'], ['of', 'IN'], ['a', 'DT'], ['~~~~~~~', 'NN'], [',', ','], [\"'\", \"''\"], ['thought', 'JJ'], ['Alice', 'NNP'], [\"'without\", 'POS'], ['pictures', 'NNS'], ['or', 'CC'], ['~~~~~~~', 'NN'], ['?', '.'], [\"'\", \"''\"]]\n"
     ]
    }
   ],
   "source": [
    "# But now we can also modify the content!\n",
    "for l in alice_paragraph_tagged_list:\n",
    "    if l[1] == 'NN':\n",
    "        l[0] = '~~~~~~~'\n",
    "        \n",
    "print(alice_paragraph_tagged_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's define our own random set of nouns.\n",
    "NNs = [\n",
    "    \"jar of pickles\",\n",
    "    \"cotton candy\",\n",
    "    \"frisbee\",\n",
    "    \"homework\",\n",
    "    \"kitchen knife\",\n",
    "    \"baked potato\",\n",
    "    \"cellphone\",\n",
    "    \"harmonica\",\n",
    "    \"banjo\",\n",
    "    \"drama\",\n",
    "    \"office\",\n",
    "    \"desk\",\n",
    "    \"celebration\",\n",
    "    \"wife\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['Alice', 'NNP'], ['was', 'VBD'], ['beginning', 'VBG'], ['to', 'TO'], ['get', 'VB'], ['very', 'RB'], ['tired', 'JJ'], ['of', 'IN'], ['sitting', 'VBG'], ['by', 'IN'], ['her', 'PRP$'], ['homework', 'NN'], ['on', 'IN'], ['the', 'DT'], ['kitchen knife', 'NN'], [',', ','], ['and', 'CC'], ['of', 'IN'], ['having', 'VBG'], ['kitchen knife', 'NN'], ['to', 'TO'], ['do', 'VB'], [':', ':'], ['once', 'RB'], ['or', 'CC'], ['twice', 'VB'], ['she', 'PRP'], ['had', 'VBD'], ['peeped', 'VBN'], ['into', 'IN'], ['the', 'DT'], ['jar of pickles', 'NN'], ['her', 'PRP$'], ['jar of pickles', 'NN'], ['was', 'VBD'], ['reading', 'VBG'], [',', ','], ['but', 'CC'], ['it', 'PRP'], ['had', 'VBD'], ['no', 'DT'], ['pictures', 'NNS'], ['or', 'CC'], ['conversations', 'NNS'], ['in', 'IN'], ['it', 'PRP'], [',', ','], [\"'and\", 'VB'], ['what', 'WP'], ['is', 'VBZ'], ['the', 'DT'], ['cotton candy', 'NN'], ['of', 'IN'], ['a', 'DT'], ['jar of pickles', 'NN'], [',', ','], [\"'\", \"''\"], ['thought', 'JJ'], ['Alice', 'NNP'], [\"'without\", 'POS'], ['pictures', 'NNS'], ['or', 'CC'], ['kitchen knife', 'NN'], ['?', '.'], [\"'\", \"''\"]]\n"
     ]
    }
   ],
   "source": [
    "# Replace all noun slots with a random noun from our custom list.\n",
    "from random import randint\n",
    "\n",
    "for l in alice_paragraph_tagged_list:\n",
    "    if l[1] == 'NN':\n",
    "        replacement = NNs[randint(0,4)]\n",
    "        l[0] = replacement\n",
    "\n",
    "print(alice_paragraph_tagged_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Alice was beginning to get very tired of sitting by her homework on the kitchen knife , and of having kitchen knife to do : once or twice she had peeped into the jar of pickles her jar of pickles was reading , but it had no pictures or conversations in it , 'and what is the cotton candy of a jar of pickles , ' thought Alice 'without pictures or kitchen knife ? '\n"
     ]
    }
   ],
   "source": [
    "# Return the data back to a format for reading.\n",
    "output = ''\n",
    "\n",
    "for l in alice_paragraph_tagged_list:\n",
    "    output += (' ' + l[0])\n",
    "    \n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span id=\"07\">Going further</span>\n",
    "\n",
    "This is clearly very silly. But it's the groundwork for quite few interesting possibilities. You could...\n",
    "\n",
    "- Make global replacements so that all instances of X get replaced with Y\n",
    "- Mix multiple texts by replacing nouns in one text with nouns from another\n",
    "- Re-make [Oulipo](https://en.wikipedia.org/wiki/Oulipo)'s famous S+7 procedure by using an external dictionary\n",
    "- Replace all adjectives with their antonyms\n",
    "- Start to think about article matching\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
